<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://daseinda.github.io//feed.xml" rel="self" type="application/atom+xml" /><link href="https://daseinda.github.io//" rel="alternate" type="text/html" hreflang="en" /><updated>2023-11-07T21:22:20+00:00</updated><id>https://daseinda.github.io//feed.xml</id><title type="html">blank</title><subtitle>A lifelong learner interested in the modern world.
</subtitle><entry><title type="html">The pure C implementation for Transformer</title><link href="https://daseinda.github.io//blog/2023/transformer-c/" rel="alternate" type="text/html" title="The pure C implementation for Transformer" /><published>2023-11-01T22:32:51+00:00</published><updated>2023-11-01T22:32:51+00:00</updated><id>https://daseinda.github.io//blog/2023/transformer-c</id><content type="html" xml:base="https://daseinda.github.io//blog/2023/transformer-c/"><![CDATA[<h2 id="the-visualization-of-tansformer-structure">The visualization of Tansformer structure</h2>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/Transformer_C/transformer_str.jpg" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[1]</div>
</center>

<h2 id="vision-transformer">Vision Transformer</h2>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/Transformer_C/vit.jpg" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[2]</div>
</center>

<h3 id="code-for-vits-matrix-to-patchs">Code for ViT’s matrix to patchs</h3>
<pre><code class="language-C">    #define Feature2Patch(input,output)											\
    {																			\
        size_t image_size = GETLENGTH(*input);									\	
        size_t patch_size=GETLENGTH(**output);									\
        size_t patch_num_row = image_size/patch_size;							\		
        FOREACH(o0, GETLENGTH(output))											\
            FOREACH(o1, GETLENGTH(output))										\
                FOREACH(o2, GETLENGTH(output))									\
                    FOREACH(o3, GETLENGTH(output))								\
                        output[o0][o1][o2][o3]=input[o1][o0/patch_num_row*patch_size+o2][o0%patch_num_row*patch_size+o3];\
    }

    for(int i=0;i&lt;28;i++){
	    for(int j=0;j&lt;28;j++){
			features.input[0][i][j]=i*28+j;
		}
	}
	printf("###########%d\n",features.input[0][1][2]);
	Feature2Patch(features.input, features.input_patch);
	for(int i=0;i&lt;PATCH_NUM;i++){
		for(int j=0;j&lt;PATCH_SIZE;j++){
			printf("\n");
			for(int k=0;k&lt;PATCH_SIZE;k++){
				printf("output[%d][0]%d[%d] is %f  ", i,j,k,features.input_patch[i][0][j][k]);
			}
		}
		printf("\n");
		sleep(2);
	}

</code></pre>
<p>I am recording my Transformer C implementation for Intel SGX usage. Because Intel SGX interfaces can only be written in pure C, even C++ would not work. Assume the dataset is MNIST, the size of the black-white image matrix is (1,28,28). The model parameters matrix number group used in the implementation is 3-dimensional. There are 4-dimensional number group in input/output matrices to record the products during the learning process. Note that each channel of the input matrix, owns an independent group of kernel, but each channel’s kernel parameter update share the same total final output of this layer.</p>

<h2 id="reference">Reference</h2>
<div id="refer-anchor-1"></div>

<ul>
  <li>[1] https://arxiv.org/pdf/1706.03762.pdf</li>
</ul>

<div id="refer-anchor-1"></div>

<ul>
  <li>[2] https://arxiv.org/pdf/2010.11929.pdf</li>
</ul>]]></content><author><name></name></author><category term="CNN_C" /><summary type="html"><![CDATA[The pure C implementation for Transformer]]></summary></entry><entry><title type="html">The pure C implementation for Alexnet</title><link href="https://daseinda.github.io//blog/2023/alexnet-c/" rel="alternate" type="text/html" title="The pure C implementation for Alexnet" /><published>2023-10-10T22:32:51+00:00</published><updated>2023-10-10T22:32:51+00:00</updated><id>https://daseinda.github.io//blog/2023/alexnet-c</id><content type="html" xml:base="https://daseinda.github.io//blog/2023/alexnet-c/"><![CDATA[<p>I am recording my Alexnet C implementation for Intel SGX usage. Because Intel SGX interfaces can only be written in pure C, even C++ would not work. Assume the dataset is MNIST, the size of the black-white image matrix is (1,28,28). The model parameters matrix number group used in the implementation is 3-dimensional. There are 4-dimensional number group in input/output matrices to record the products during the learning process. Note that each channel of the input matrix, owns an independent group of kernel, but each channel’s kernel parameter update share the same total final output of this layer.</p>

<p>Since much detailed operations such as Convolution/Backward/Activation/Pool have been explained on last blog: The pure C implementation for LeNet5. These would be omitted here.</p>

<h2 id="the-visualization-of-alexnet-structure">The visualization of Alexnet structure</h2>

<!-- <img src="/assets/img/blogs/2023/LeNet5_C/LeNet5_Structure.jpg"  width="500">  -->
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/AlexNet_C/alexnet_structure.jpg" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[1] The structure of AlexNet</div>
</center>

<h2 id="alexnet-strcuture-c-definition">AlexNet strcuture C definition</h2>
<pre><code class="language-C">typedef struct AlexNet
{
	double weight1[INPUT][LAYER1][LENGTH_KERNEL][LENGTH_KERNEL];//Layer1 kernel
	double weight2[LAYER1][LAYER2][LENGTH_KERNEL][LENGTH_KERNEL];//Layer2 Kernel
	double weight3[LAYER2][LAYER3][LENGTH_KERNEL][LENGTH_KERNEL];//Layer3 Kernel
	//double weight5_6[LAYER5 * LENGTH_FEATURE5 * LENGTH_FEATURE5][OUTPUT];
	double weight4[LAYER3][LAYER4][LENGTH_KERNEL][LENGTH_KERNEL];//Layer4 Kernel
	double weight5[LAYER4][LAYER5][LENGTH_KERNEL][LENGTH_KERNEL];//Layer5 Kernel

	double fc1[LAYER5*LENGTH_FEATURE5_2*LENGTH_FEATURE5_2][FC1_OUTPUT];
	double fc2[FC1_OUTPUT][FC2_OUTPUT];
	double fc3[FC2_OUTPUT][FC3_OUTPUT];

	double bias1[LAYER1];
	double bias2[LAYER2];
	double bias3[LAYER3];
	double bias4[LAYER4];
	double bias5[LAYER5];

	double bias_fc1[LAYER3];
	double bias_fc2[LAYER4];
	double bias_fc3[LAYER5];

}AlexNet;
</code></pre>

<h2 id="the-data-structure-of-input-and-output-during-learning">The data structure of input and output during learning</h2>
<pre><code class="language-C">    typedef struct Feature
    {
        double input[INPUT][LENGTH_FEATURE0][LENGTH_FEATURE0];

        double layer1_conv[LAYER1][LENGTH_FEATURE1_1][LENGTH_FEATURE1_1];
        double layer1_pool[LAYER1][LENGTH_FEATURE1_2][LENGTH_FEATURE1_2];

        double layer2_conv[LAYER2][LENGTH_FEATURE2_1][LENGTH_FEATURE2_1];
        double layer2_pool[LAYER3][LENGTH_FEATURE2_2][LENGTH_FEATURE2_2];

        double layer3_conv[LAYER4][LENGTH_FEATURE3_1][LENGTH_FEATURE3_1];
        
        double layer4_conv[LAYER5][LENGTH_FEATURE4_1][LENGTH_FEATURE4_1];


        double layer5_conv[LAYER5][LENGTH_FEATURE5_1][LENGTH_FEATURE5_1];
        double layer5_pool[LAYER5][LENGTH_FEATURE5_2][LENGTH_FEATURE5_2];

        double fc1[FC1_OUTPUT];
        double fc2[FC2_OUTPUT];
        double fc3[FC3_OUTPUT];

        double output[OUTPUT];
    }Feature;
</code></pre>

<h2 id="the-header-pre-defined-variables-for-alexnets-hyper-parameters">The header pre-defined variables for Alexnet’s hyper-parameters</h2>
<pre><code class="language-C">    #pragma once
    #define LENGTH_KERNEL	3
    #define MAXPOOL_SIZE 2
    #define PADDING 1
    #define LENGTH_FEATURE0	28
    #define LENGTH_FEATURE1_1	(LENGTH_FEATURE0 - LENGTH_KERNEL + 2*PADDING+1) //28-3+2+1 -&gt;28*28
    #define LENGTH_FEATURE1_2	(LENGTH_FEATURE1_1/2) //14*14
    #define LENGTH_FEATURE2_1	(LENGTH_FEATURE1_2 - LENGTH_KERNEL +2*PADDING + 1) //14-3+2+1=14
    #define	LENGTH_FEATURE2_2	(LENGTH_FEATURE2_1/2)  //7*7
    #define LENGTH_FEATURE3_1	(LENGTH_FEATURE2_2 - LENGTH_KERNEL +2*PADDING+ 1) //7*7
    #define LENGTH_FEATURE4_1	(LENGTH_FEATURE3_1 - LENGTH_KERNEL +2*PADDING+ 1)//7*7
    #define MAXPOOL5_2_KERNEL 3
    #define MAXPOOL5_2_STRIDE 2

    #define LENGTH_FEATURE5_1	(LENGTH_FEATURE4_1 - LENGTH_KERNEL+2*PADDING+ 1)	//7*7
    #define LENGTH_FEATURE5_2	((LENGTH_FEATURE5_1 - MAXPOOL5_2_KERNEL)/MAXPOOL5_2_STRIDE+ 1) //(7-3)/2 +1 = 3 no padding

    #define FC1_OUTPUT	1024
    #define FC2_OUTPUT	512
    #define FC3_OUTPUT	10


    #define INPUT			1
    #define LAYER1			32
    #define LAYER2			64
    #define LAYER3			128
    #define LAYER4			256
    #define LAYER5			256

    #define OUTPUT          10

    #define ALPHA 0.5


    typedef unsigned char uint8;
    typedef uint8 image[28][28];

</code></pre>

<h2 id="forward">Forward</h2>
<pre><code class="language-C">static void forward(AlexNet *alexnet, double(*action)(double))
{
	CONVOLUTION_FORWARD(features.input, features.layer1_conv, alexnet-&gt;weight1, alexnet-&gt;bias1, action);
	SUBSAMP_MAX_FORWARD(features.layer1_conv, features.layer1_pool);

	CONVOLUTION_FORWARD(features.layer1_pool, features.layer2_conv, alexnet-&gt;weight2, alexnet-&gt;bias2, action);
	SUBSAMP_MAX_FORWARD(features.layer2_conv, features.layer2_pool);

	CONVOLUTION_FORWARD(features.layer2_pool, features.layer3_conv, alexnet-&gt;weight3, alexnet-&gt;bias3, action);
	
	CONVOLUTION_FORWARD(features.layer3_conv, features.layer4_conv, alexnet-&gt;weight4, alexnet-&gt;bias4, action);

	CONVOLUTION_FORWARD(features.layer4_conv, features.layer5_conv, alexnet-&gt;weight5, alexnet-&gt;bias5, action);
	SUBSAMP_MAX_FORWARD(features.layer5_conv, features.layer5_pool);

	// Matrix_FC(features-&gt;layer5_pool, features-&gt;fc1, alexnet-&gt;fc1);
	// FC(features-&gt;fc1, features-&gt;fc2, alexnet-&gt;fc2);
	// FC(features-&gt;fc2, features-&gt;fc3, alexnet-&gt;fc3);
	DOT_PRODUCT_FORWARD(features.layer5_pool, features.fc1, alexnet-&gt;fc1, alexnet-&gt;bias_fc1, action);
	DOT_PRODUCT_FORWARD(features.fc1, features.fc2, alexnet-&gt;fc2, alexnet-&gt;bias_fc2, action);
	DOT_PRODUCT_FORWARD(features.fc2, features.output, alexnet-&gt;fc3, alexnet-&gt;bias_fc3, action);
	// CONVOLUTION_FORWARD(features-&gt;layer2, features-&gt;layer3, lenet-&gt;weight2_3, lenet-&gt;bias2_3, action);
	// SUBSAMP_MAX_FORWARD(features-&gt;layer3, features-&gt;layer4);
	// CONVOLUTION_FORWARD(features-&gt;layer4, features-&gt;layer5, lenet-&gt;weight4_5, lenet-&gt;bias4_5, action);
	// DOT_PRODUCT_FORWARD(features-&gt;layer5, features-&gt;output, lenet-&gt;weight5_6, lenet-&gt;bias5_6, action);
}
</code></pre>
<h2 id="backward">Backward</h2>

<pre><code class="language-C">    static void backward(AlexNet *alexnet, double(*actiongrad)(double))
    {
        //printf("Here is Backward\n");
        DOT_PRODUCT_BACKWARD(features.fc2, errors.fc2, errors.output, alexnet-&gt;fc3, deltas.fc3, deltas.bias_fc3, actiongrad);
        DOT_PRODUCT_BACKWARD(features.fc1, errors.fc1, errors.fc2, alexnet-&gt;fc2, deltas.fc2, deltas.bias_fc2, actiongrad);
        DOT_PRODUCT_BACKWARD(features.layer5_pool, errors.layer5_pool, errors.fc1,alexnet-&gt;fc1, deltas.fc1, deltas.bias_fc1, actiongrad)
        
        SUBSAMP_MAX_BACKWARD(features.layer5_conv, errors.layer5_conv, errors.layer5_pool);
        
        CONVOLUTION_BACKWARD(features.layer4_conv, errors.layer4_conv, errors.layer5_conv, alexnet-&gt;weight5, deltas.weight5, deltas.bias5, actiongrad);

        CONVOLUTION_BACKWARD(features.layer3_conv, errors.layer3_conv, errors.layer4_conv, alexnet-&gt;weight4, deltas.weight4, deltas.bias4, actiongrad);

        CONVOLUTION_BACKWARD(features.layer2_pool, errors.layer2_conv, errors.layer3_conv, alexnet-&gt;weight3, deltas.weight3, deltas.bias3, actiongrad);
        SUBSAMP_MAX_BACKWARD(features.layer2_conv, errors.layer2_conv, errors.layer2_pool);

        CONVOLUTION_BACKWARD(features.layer1_pool, errors.layer1_pool, errors.layer2_conv, alexnet-&gt;weight2, deltas.weight2, deltas.bias2, actiongrad);
        SUBSAMP_MAX_BACKWARD(features.layer1_conv, errors.layer1_conv, errors.layer1_pool);

        CONVOLUTION_BACKWARD(features.input, errors.input, errors.layer1_conv, alexnet-&gt;weight1, deltas.weight1, deltas.bias1, actiongrad);
    }


</code></pre>

<p>Because of the memory limitation, I eliminate the buffer[ ] here, which can also save the execution time and resources, but decreases the code readability. Maybe also can eliminate it in LeNet-5, when necessary.</p>

<p>maxpool backward does not record the max specific position of the input matrix, it simply aplies the start point of original max kernel</p>

<h2 id="implementation-draft-note">Implementation draft note</h2>
<h3 id="padding-test">Padding test</h3>

<p>```C
	double input[2][4][4]={1};
	double input_pad[2][6][6]={0};
        for(int i=0;i&lt;4;i++){
            for(int j=0;j&lt;4;j++){
                input[0][i][j] =1;
                printf(“[%d][%d] %f”,i,j,input[0][i][j]);</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        }
        printf("\n");
    }
    printf("\n");
    for(int i=0;i&lt;4;i++){
        for(int j=0;j&lt;4;j++){
            input[1][i][j] =2;
            printf("[%d][%d] %f",i,j,input[1][i][j]);
            
        }
        printf("\n");
    }
    PADDING_fill(input_pad,input);
    printf("\n");
    for(int i=0;i&lt;6;i++){
        for(int j=0;j&lt;6;j++){
            printf("[0][%d][%d] %f",i,j,input_pad[0][i][j]);
        }
        printf("\n");
    }
    printf("\n");
        for(int i=0;i&lt;6;i++){
        for(int j=0;j&lt;6;j++){
            printf("[1][%d][%d] %f",i,j,input_pad[1][i][j]);
        }
        printf("\n");
    }

    sleep(300);
```
</code></pre></div></div>

<h2 id="if-the-group-is-not-cited-as-diemsional-test">If the group is not cited as diemsional test:</h2>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```C
            double test[2][2][2]={ 0 };
        for(int i=0;i&lt;2;i++){
            for(int j=0;j&lt;2;j++){
                for(int k=0;k&lt;2;k++){
                        test[i][j][k] = (i)*4+(j*2)+k+1;
        }
            }}
        for(int i=0;i&lt;8;i++){
            printf("%f\n",test[i]);
        }
    printf("DOT test\n");
        for(int i=0;i&lt;2;i++){
            for(int j=0;j&lt;2;j++){
                for(int k=0;k&lt;2;k++){
                        printf("%f\n",test[i][j][k]);
        }
            }}
    ```
    
    The output would be:

    ```C
    0.000000
    0.000000
    0.000000
    0.000000
    0.000000
    0.000000
    0.000000
    0.000000
    DOT test
    1.000000
    2.000000
    3.000000
    4.000000
    5.000000
    6.000000
    7.000000
    8.000000

    ```

    Test2:
        ```C
        	double test[2][1][1]={ 0 };
            // for(int i=0;i&lt;2;i++){
            // 	for(int j=0;j&lt;2;j++){
            // 		for(int k=0;k&lt;2;k++){
            // 				test[i][j][k] = (i)*4+(j*2)+k+1;
            // }
            //	}}
            test[0][0][0]=1;
            test[1][0][0]=2;
            for(int i=0;i&lt;2;i++){
                printf("%f\n",test[i]);
            }
        printf("DOT test\n");
        printf("The ((double *)test[0]) is %f\n",((double *)test)[0]);
        printf("%f\n",test[1]);

            // for(int i=0;i&lt;2;i++){
            // 	for(int j=0;j&lt;2;j++){
            // 		for(int k=0;k&lt;2;k++){
            // 				printf("%f\n",test[i][j][k]);
            // }
            // 	}}
            sleep(300);
```

The output is:
```C
    Here is TrainBatch 0
    0.000000
    0.000000
    DOT test
    The ((double *)test[0]) is 1.000000
    1.000000
    ^C
```
</code></pre></div></div>]]></content><author><name></name></author><category term="CNN_C" /><summary type="html"><![CDATA[The pure C implementation for Alexnet]]></summary></entry><entry><title type="html">The pure C implementation for ResNet</title><link href="https://daseinda.github.io//blog/2023/resnet-c/" rel="alternate" type="text/html" title="The pure C implementation for ResNet" /><published>2023-08-01T22:32:51+00:00</published><updated>2023-08-01T22:32:51+00:00</updated><id>https://daseinda.github.io//blog/2023/resnet-c</id><content type="html" xml:base="https://daseinda.github.io//blog/2023/resnet-c/"><![CDATA[<h2 id="the-visualization-of-resnet-structure">The visualization of ResNet structure</h2>

<!-- <img src="/assets/img/blogs/2023/ResNet_C/resnet_str.jpg"  width="500">  -->

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/ResNet_C/resnet_str.png" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[2]</div>
</center>

<p>I am recording my ResNet C implementation for Intel SGX usage. Because Intel SGX interfaces can only be written in pure C, even C++ would not work. Assume the dataset is MNIST, the size of the black-white image matrix is (1,28,28). The model parameters matrix number group used in the implementation is 3-dimensional. There are 4-dimensional number group in input/output matrices to record the products during the learning process. Note that each channel of the input matrix, owns an independent group of kernel, but each channel’s kernel parameter update share the same total final output of this layer.</p>

<h2 id="resnet-structure">ResNet Structure</h2>
<pre><code class="language-C">
  typedef struct ResBlock1
  {
    double weight1[RES1_CHANNEL][RES1_CHANNEL][RES_LENGTH_KERNEL][RES_LENGTH_KERNEL];
    double weight2[RES1_CHANNEL][RES1_CHANNEL][RES_LENGTH_KERNEL][RES_LENGTH_KERNEL];
    double bias1[RES1_CHANNEL];
    double bias2[RES1_CHANNEL];	
  }ResBlock1;


  typedef struct ResBlock2
  {
    double weight1[RES2_CHANNEL][RES2_CHANNEL][RES_LENGTH_KERNEL][RES_LENGTH_KERNEL];
    double weight2[RES2_CHANNEL][RES2_CHANNEL][RES_LENGTH_KERNEL][RES_LENGTH_KERNEL];	
    double bias1[RES1_CHANNEL];
    double bias2[RES1_CHANNEL];	
  }ResBlock2;	


  typedef struct Res1_Feature
  {
    double input_pad[RES1_CHANNEL][14][14];
    double conv1[RES1_CHANNEL][12][12];

    double conv1_pad[RES1_CHANNEL][14][14];
    double conv2[RES1_CHANNEL][12][12];
  }Res1_Feature;

  typedef struct Res2_Feature
  {
    double input_pad[RES2_CHANNEL][6][6];
    double conv1[RES2_CHANNEL][4][4];
    double conv1_pad[RES2_CHANNEL][6][6];
    double conv2[RES2_CHANNEL][4][4];
  }Res2_Feature;



  typedef struct ResNet
  {
    double weight1[INPUT][LAYER1][LENGTH_KERNEL][LENGTH_KERNEL];//Layer1 kernel
    //maxpool
    ResBlock1 res1;
    double weight2[LAYER1][LAYER2][LENGTH_KERNEL][LENGTH_KERNEL];//Layer2 Kernel
    //maxpool
    ResBlock2 res2;

    double fc[512][OUTPUT];


    double bias1[LAYER1];
    double bias2[LAYER2];


    double bias_fc[OUTPUT];

  }ResNet;

</code></pre>

<h2 id="resnet-implementation">ResNet implementation</h2>
<pre><code class="language-C">#define CONVOLUTION_RES_FORWARD(res_input,input,output,weight,bias,action)		\
{																				\
	for (int x = 0; x &lt; GETLENGTH(weight); ++x)									\
		for (int y = 0; y &lt; GETLENGTH(*weight); ++y)							\
			CONVOLUTE_VALID(input[x], output[y], weight[x][y]);					\
	FOREACH(i, GETCOUNT(output))												\
		((double*)output)[i] += ((double*)res_input)[i];							\
	FOREACH(j, GETLENGTH(output))												\
		FOREACH(i, GETCOUNT(output[j]))											\
		((double *)output[j])[i] = action(((double *)output[j])[i] + bias[j]);	\
}
#define ResBlock_Forward(input,output,res,action)								\
{																				\
	PADDING_fill(output.input_pad,input);										\
	CONVOLUTION_FORWARD(output.input_pad,output.conv1,res.weight1,res.bias1,action);\
	PADDING_fill(output.conv1_pad,output.conv1);								\
	CONVOLUTION_RES_FORWARD(input, output.conv1_pad,output.conv2,res.weight2,res.bias2,action);\
}																					\
#define ResBlock_Backward(res,res_error,res_weight,res_deltas,actiongrad)	\
{																			\
	CONVOLUTION_BACKWARD(res.conv1_pad, res_error.conv1_pad,res_error.conv2,res_weight.weight2,res_deltas.weight2,res_deltas.bias2,actiongrad);\
	PADDING_remove(res_error.conv1,res_error.conv1_pad);											\
	CONVOLUTION_BACKWARD(res.input_pad, res_error.input_pad,res_error.conv1,res_weight.weight1,res_deltas.weight1,res_deltas.bias1,actiongrad);\
}
</code></pre>

<h2 id="questions-that-should-make-a-attention-during-the-implementation">Questions that should make a attention during the implementation</h2>

<ul>
  <li>learning_rate=10 would cause gradient dissapearance</li>
  <li>1/300*x would cause gradient dissappearance in comparison with x/300;</li>
</ul>]]></content><author><name></name></author><category term="CNN_C" /><summary type="html"><![CDATA[The pure C implementation for ResNet]]></summary></entry><entry><title type="html">The pure C implementation for LeNet5</title><link href="https://daseinda.github.io//blog/2023/lenet5-c/" rel="alternate" type="text/html" title="The pure C implementation for LeNet5" /><published>2023-06-20T22:32:51+00:00</published><updated>2023-06-20T22:32:51+00:00</updated><id>https://daseinda.github.io//blog/2023/lenet5-c</id><content type="html" xml:base="https://daseinda.github.io//blog/2023/lenet5-c/"><![CDATA[<h2 id="the-visualization-of-lenet5-structure">The visualization of LeNet5 structure</h2>

<!-- <img src="/assets/img/blogs/2023/LeNet5_C/LeNet5_Structure.jpg"  width="500">  -->

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/LeNet5_C/LeNet5_Structure.jpg" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[2]</div>
</center>

<p>I am recording my LeNet5 C implementation for Intel SGX usage. Because Intel SGX interfaces can only be written in pure C, even C++ would not work. Assume the dataset is MNIST, the size of the black-white image matrix is (1,28,28). The model parameters matrix number group used in the implementation is 3-dimensional. There are 4-dimensional number group in input/output matrices to record the products during the learning process. Note that each channel of the input matrix, owns an independent group of kernel, but each channel’s kernel parameter update share the same total final output of this layer.</p>

<h2 id="how-to-calculate-the-matrix-size-after-layer-operations">How to calculate the matrix size after layer operations:</h2>

<h3 id="convolution">Convolution</h3>
<p>Assumptions:</p>
<ul>
  <li>The size of input matrix: (dimentional,W,W)</li>
  <li>The size of kernel: (kernel_dimentional, F,F)</li>
  <li>The step size: S</li>
  <li>Padding: P</li>
</ul>

\[N = \frac{W-F+2P}{S}+1\]

<p>The size of output matrix size is N.</p>

<h2 id="the-meaning-of-batch-size">The meaning of Batch Size</h2>
<ul>
  <li>Batch size is the number of training images between each backward/parameter updates.</li>
  <li>Batch size training can be parallelized with openmp at C. But not work at Intel SGX up to now(I am trying to apply the openmp in Intel SGX at the present).</li>
</ul>

<h2 id="convolution-implementation">Convolution implementation</h2>
<pre><code class="language-C">    #define CONVOLUTION_FORWARD(input,output,weight,bias,action)					\
    {																				
      for (int x = 0; x &lt; GETLENGTH(weight); ++x)									\
        for (int y = 0; y &lt; GETLENGTH(*weight); ++y)							\
          CONVOLUTE_VALID(input[x], output[y], weight[x][y]);					\
      FOREACH(j, GETLENGTH(output))												\
        FOREACH(i, GETCOUNT(output[j]))											\
        ((double *)output[j])[i] = action(((double *)output[j])[i] + bias[j]);	\
    }
</code></pre>
<ul>
  <li>The input[x] is the channel of the input matrix.</li>
  <li>The output[y] is the number of feature map for input image’s x channel. For each image’s x channel, the first (for) loop plus each x convolution computation operation to the output[y], and achieve the convolution performance.</li>
</ul>

<h2 id="convolution-backward-implementation">Convolution Backward Implementation</h2>
<pre><code class="language-C">  #define CONVOLUTION_BACKWARD(input,inerror,outerror,weight,wd,bd,actiongrad)\
  {																			\
    for (int x = 0; x &lt; GETLENGTH(weight); ++x)								\
      for (int y = 0; y &lt; GETLENGTH(*weight); ++y)						\
        CONVOLUTE_FULL(outerror[y], inerror[x], weight[x][y]);			\
    FOREACH(i, GETCOUNT(inerror))											\
      ((double *)inerror)[i] *= actiongrad(((double *)input)[i]);			\
    FOREACH(j, GETLENGTH(outerror))											\
      FOREACH(i, GETCOUNT(outerror[j]))									\
      bd[j] += ((double *)outerror[j])[i];								\
    for (int x = 0; x &lt; GETLENGTH(weight); ++x)								\
      for (int y = 0; y &lt; GETLENGTH(*weight); ++y)						\
        CONVOLUTE_VALID(input[x], wd[x][y], outerror[y]);				\
  }
</code></pre>
<ul>
  <li>The backward of convolution is indeed the gradient calculation iterated from output layer to input layer, each layer’s gradient depends on the next layer gradient and the layer’s current parameters. From the implementation, we can figure out one shortage of resnet, which originally should make it competitive to Transformer in my opinion. That the res-connection-previous-layer’s gradient in resnet should participate into the res-connection-current-layer’s gradient parameter update on numerial/optimization/mathematical aspect. Due to the limitation of python engineering implementation, such gradient-connection are omitted, and the previous input value simply takes part in the current input. I also would not intend to discuss such missing feature for res-connection at the present thesis work due to the large work-load I have had. But may research it in the future spare time.</li>
  <li>Assume a conv layer in the model, the kernel size is m*m, each output off this layer \(y_{1}.....y_{n}\), would update this layer kernel’s parameters \(\omega_{1}\) …… \(\omega_{m^{2}}\). L is the loss.</li>
</ul>

\[\frac{\partial{L}}{\partial{\omega_{i}}} =\frac{\partial{L}}{\partial{y_{1}}}*\frac{\partial{y_{1}}}{\partial{\omega_{i}}}+......\frac{\partial{L}}{\partial{y_{n}}}*\frac{\partial{y_{n}}}{\partial{\omega_{i}}}\]

<p>For example:</p>

\[\frac{\partial{L}}{\partial{\omega_{1}}} =\frac{\partial{L}}{\partial{y_{1}}}*\frac{\partial{y_{1}}}{\partial{\omega_{1}}}+......\frac{\partial{L}}{\partial{y_{n}}}*\frac{\partial{y_{n}}}{\partial{\omega_{1}}}\]

\[\frac{\partial{L}}{\partial{\omega_{2}}} =\frac{\partial{L}}{\partial{y_{1}}}*\frac{\partial{y_{1}}}{\partial{\omega_{2}}}+......\frac{\partial{L}}{\partial{y_{n}}}*\frac{\partial{y_{n}}}{\partial{\omega_{2}}}\]

\[......\]

\[\frac{\partial{L}}{\partial{\omega_{m*m}}} =\frac{\partial{L}}{\partial{y_{1}}}*\frac{\partial{y_{1}}}{\partial{\omega_{m*m}}}+......\frac{\partial{L}}{\partial{y_{n}}}*\frac{\partial{y_{n}}}{\partial{\omega_{m*m}}}\]

<ul>
  <li>
    <p>\(\frac{\partial{y_{j}}}{\partial{\omega_{i}}}\) is the input value that participating into the output value \(y_{j}\)’s calculation, and multiplying by \(\omega_{i}\)</p>
  </li>
  <li>
    <p>The kernel parameter update can also follow the convolution-order path, since the sum of the update would not change. For example, the first update:</p>
  </li>
</ul>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/LeNet5_C/update_conv_order.png" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Backward Parameter update order following convolution order</div>
</center>

<p>So backward and forward convolution share the same calculation multiplier:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```C 
    #define CONVOLUTE_VALID(input,output,weight)											
    {																						
      FOREACH(o0,GETLENGTH(output))														
        FOREACH(o1,GETLENGTH(*(output)))												
          FOREACH(w0,GETLENGTH(weight))												
            FOREACH(w1,GETLENGTH(*(weight)))										
              (output)[o0][o1] += (input)[o0 + w0][o1 + w1] * (weight)[w0][w1];
    }
```
</code></pre></div></div>

<h2 id="bias-backward-propagation-implementation">Bias Backward Propagation Implementation:</h2>
<p>Assume a conv layer in the model, the kernel size is m*m, each output off this layer \(y_{1}.....y_{n}\), would update this layer kernel’s parameters \(\omega_{1}\) …… \(\omega_{m^{2}}\). L is the loss. b denote bias for each output feature map.</p>

\[\frac{\partial{L}}{\partial{b_{i}}} = \frac{\partial{L}}{\partial{y_{i}}}*\frac{\partial{y_{i}}}{\partial{b_{i}}}+......+ \frac{\partial{L}}{\partial{y_{j \neq i}}}*\frac{\partial{y_{j \neq i}}}{\partial{b_{i}}}\]

\[\frac{\partial{y_{j \neq i}}}{\partial{b_{i}}}=0\]

\[\frac{\partial{y_{i}}}{\partial{b_{i}}} = 1\]

\[\frac{\partial{L}}{\partial{b_{i}}} = \frac{\partial{L}}{\partial{y_{i}}}\]

<h2 id="activation-backward">Activation backward</h2>

<ul>
  <li>
    <p>There is a interesting phenomenon for ReLU activation function, that though it is non-linear, if justify is not needed. Because the \(\frac{\partial{ReLU}}{\partial{y}} * \frac{\partial{y}}{\partial{\omega_{i}}} = \frac{\partial{y}}{\partial{\omega_{i}}} = x_{i}\)</p>
  </li>
  <li>
    <p><strong><em>I am wondering during the backward process, if “if-justify” operation is implemented for other types of non-linear activation functions implement, or they use the output directly, or they do not need it just like ReLU.</em></strong></p>
  </li>
</ul>

<h2 id="pooling-backward-propagation-implementation">Pooling Backward Propagation Implementation</h2>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/LeNet5_C/maxpool_backward.png" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Max Pooling Backward Mechanism</div>
</center>

<ul>
  <li>MaxPooling(Sub-sampling Layer) is used in the LeNet5 implementation</li>
</ul>

<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/LeNet5_C/avgpool_backward.jpg" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">Average Pooling Backward Mechanism</div>
</center>

<h2 id="softmax">Softmax</h2>

<pre><code class="language-C">  static inline void softmax(double input[OUTPUT], double loss[OUTPUT], int label, int count)
  {
    double inner = 0;
    for (int i = 0; i &lt; count; ++i)
    {
      double res = 0;
      for (int j = 0; j &lt; count; ++j)
      {
        res += exp(input[j] - input[i]);
      }
      loss[i] = 1. / res;
      inner -= loss[i] * loss[i];
    }
    inner += loss[label];
    for (int i = 0; i &lt; count; ++i)
    {
      loss[i] *= (i == label) - loss[i] - inner;
    }
  }
</code></pre>

\[S_{i}=\frac{e^{y_{i}}}{\sum_{j} e^{y_{j}}} = \frac{1}{\sum_{j} e^{y_{j}-y_{i}}}\]

<ul>
  <li>loss is \(S_{i}\)</li>
</ul>

<h2 id="softmax-backward">Softmax Backward</h2>

\[S_{i}=\frac{e^{y_{i}}}{\sum_{j} e^{y_{j}}}\]

\[\frac{\partial{L}}{\partial{y_{i}}} = \frac{\partial{L}}{\partial{Softmax}} * \frac{\partial{Softmax}}{\partial{y_{i}}}\]

<h2 id="preprocessing-load_input">PreProcessing load_input</h2>
<ul>
  <li>Add padding =2 to input matrix, the output matrix is N = 28+2*2=32. Achieve by create a layer0 matrix with required size of 32,32, then fill in image’s data from 3 to 30(number group from 2 to 29)</li>
  <li>
    <p>Standardlization and normalization</p>

    <pre><code class="language-C">   static inline void load_input(Feature *features, image input)
   {
     double (*layer0)[LENGTH_FEATURE0][LENGTH_FEATURE0] = features-&gt;input;
     const long sz = sizeof(image) / sizeof(**input);
     double mean = 0, std = 0;
     FOREACH(j, sizeof(image) / sizeof(*input))
       FOREACH(k, sizeof(*input) / sizeof(**input))
     {
       mean += input[j][k];
       std += input[j][k] * input[j][k];
     }
     mean /= sz;
     std = sqrt(std / sz - mean*mean);
     FOREACH(j, sizeof(image) / sizeof(*input))
       FOREACH(k, sizeof(*input) / sizeof(**input))
     {
       layer0[0][j + PADDING][k + PADDING] = (input[j][k] - mean) / std;
     }
   }
</code></pre>
  </li>
</ul>

<h2 id="initial-the-strcuture-of-lenet5">Initial the strcuture of LeNet5</h2>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```C
  typedef struct LeNet5
  {
      double weight0_1[INPUT][LAYER1][LENGTH_KERNEL][LENGTH_KERNEL];
      double weight2_3[LAYER2][LAYER3][LENGTH_KERNEL][LENGTH_KERNEL];
      double weight4_5[LAYER4][LAYER5][LENGTH_KERNEL][LENGTH_KERNEL];
      double weight5_6[LAYER5 * LENGTH_FEATURE5 * LENGTH_FEATURE5][OUTPUT];
      /*bias*/
      double bias0_1[LAYER1];
      double bias2_3[LAYER3];
      double bias4_5[LAYER5];
      double bias5_6[OUTPUT];
  }LeNet5;
```
</code></pre></div></div>

<h3 id="the-explanation-for-c-struct-lenet5">The explanation for C struct LeNet5</h3>

<h4 id="c1-layer">C1 Layer</h4>
<ul>
  <li>wegiht0_1: The 1st convolution layer/kernels for the input image(size: 1,32,32), the size of this kernel is: (INPUT=1,LENGTH_KERNEL=5,LENGTH_KERNEL=5), there are LAYER1=6 kernels. The step size is 1. After the first layer, the matrix size would change from (1,28,28) to (Layer1=6, N=28,N=28), consists of 6 feature maps. no padding, padding =0;</li>
  <li>bias0_1: The bias for each kernel at C1 layer, there are LAYER1=6 bias corresponding to each feacture map.</li>
  <li>activation: relu. after each convolution operation. Replace <strong><em>CNN-POOL-RELU</em></strong> with <strong><em>CNN-RELU-POOL</em></strong> process order, the latter one is mostly used in recent cnn applications.
    <h4 id="s2-layer">S2 Layer</h4>
    <p>This layer is pure computing operations, and no weights in the layer to compute. So There are no parameters at this layer for LeNet5 C struct. There is no activation function setting for this implementation</p>
    <h5 id="down-sampling-layer">down-sampling layer</h5>
    <p>The down-sampling kernel size is (2,2). The output at this layer is 28/kernel_size = (6,14,14), consists of 6 feature maps of size(14,14).</p>
  </li>
</ul>

<h4 id="c3-layer">C3 Layer</h4>
<p>This is the third layer of LeNet5, a convolutional layer</p>
<ul>
  <li>weight2_3: LAYER2=6 is the input matrix’s dimentional from S2 Layer. LAYER3=16 is the output matrix’s dimensional from C3 layer. The kernels at this layer is (LAYER3=16, LENGTH_KERNEL = 5,5).</li>
  <li>bias2_3: The bias for the 16 kerners at layer 3.</li>
  <li>Not all feature maps from S2 will be used in C3.</li>
</ul>
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" src="/assets/img/blogs/2023/LeNet5_C/throw_connection_lenet5.PNG" width="500" />
    <br />
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[2] Not all S2's feature maps will be used in C3</div>
</center>

<ul>
  <li><strong><em>The implementation does not implement the above connenction throwing.</em></strong></li>
</ul>

<h2 id="the-data-structure-of-input-and-output-during-learning">The data structure of input and output during learning</h2>
<pre><code class="language-C">  typedef struct Feature
  {
    double input[INPUT][LENGTH_FEATURE0][LENGTH_FEATURE0];
    double layer1[LAYER1][LENGTH_FEATURE1][LENGTH_FEATURE1];
    double layer2[LAYER2][LENGTH_FEATURE2][LENGTH_FEATURE2];
    double layer3[LAYER3][LENGTH_FEATURE3][LENGTH_FEATURE3];
    double layer4[LAYER4][LENGTH_FEATURE4][LENGTH_FEATURE4];
    double layer5[LAYER5][LENGTH_FEATURE5][LENGTH_FEATURE5];
    double output[OUTPUT];
  }Feature;
</code></pre>
<ul>
  <li>
    <p>The INPUT is the channel of input 2-dimensional matrixs. The input is 3-dimensional matrix.</p>
  </li>
  <li>
    <p>The Feature data structure is the gradient versus Loss for each parameter in the model.</p>
  </li>
</ul>

<h2 id="reference">Reference</h2>
<div id="refer-anchor-1"></div>

<ul>
  <li>[1] https://zhuanlan.zhihu.com/p/41736894</li>
</ul>

<div id="refer-anchor-1"></div>

<ul>
  <li>[2] https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=726791</li>
</ul>]]></content><author><name></name></author><category term="CNN_C" /><summary type="html"><![CDATA[The pure C implementation for LeNet5]]></summary></entry></feed>