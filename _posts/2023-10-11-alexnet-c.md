---
layout: post
title: The pure C implementation for Alexnet
date: 2023-10-10 18:31:51-0401
description: The pure C implementation for Alexnet
categories: CNN_C
giscus_comments: false
related_posts: true
toc:
  sidebar: right
---
I am recording my Alexnet C implementation for Intel SGX usage. Because Intel SGX interfaces can only be written in pure C, even C++ would not work. Assume the dataset is MNIST, the size of the black-white image matrix is (1,28,28). The model parameters matrix number group used in the implementation is 3-dimensional. There are 4-dimensional number group in input/output matrices to record the products during the learning process. Note that each channel of the input matrix, owns an independent group of kernel, but each channel's kernel parameter update share the same total final output of this layer.

Since much detailed operations such as Convolution/Backward/Activation/Pool have been explained on last blog: The pure C implementation for LeNet5. These would be omitted here.

## The visualization of Alexnet structure

<!-- <img src="/assets/img/blogs/2023/LeNet5_C/LeNet5_Structure.jpg"  width="500">  -->
<center>
    <img style="border-radius: 0.3125em;
    box-shadow: 0 2px 4px 0 rgba(34,36,38,.12),0 2px 10px 0 rgba(34,36,38,.08);" 
    src="/assets/img/blogs/2023/AlexNet_C/alexnet_structure.jpg" width="500">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">[1] The structure of AlexNet</div>
</center>


## AlexNet strcuture C definition
```C
typedef struct AlexNet
{
	double weight1[INPUT][LAYER1][LENGTH_KERNEL][LENGTH_KERNEL];//Layer1 kernel
	double weight2[LAYER1][LAYER2][LENGTH_KERNEL][LENGTH_KERNEL];//Layer2 Kernel
	double weight3[LAYER2][LAYER3][LENGTH_KERNEL][LENGTH_KERNEL];//Layer3 Kernel
	//double weight5_6[LAYER5 * LENGTH_FEATURE5 * LENGTH_FEATURE5][OUTPUT];
	double weight4[LAYER3][LAYER4][LENGTH_KERNEL][LENGTH_KERNEL];//Layer4 Kernel
	double weight5[LAYER4][LAYER5][LENGTH_KERNEL][LENGTH_KERNEL];//Layer5 Kernel

	double fc1[LAYER5*LENGTH_FEATURE5_2*LENGTH_FEATURE5_2][FC1_OUTPUT];
	double fc2[FC1_OUTPUT][FC2_OUTPUT];
	double fc3[FC2_OUTPUT][FC3_OUTPUT];

	double bias1[LAYER1];
	double bias2[LAYER2];
	double bias3[LAYER3];
	double bias4[LAYER4];
	double bias5[LAYER5];

	double bias_fc1[LAYER3];
	double bias_fc2[LAYER4];
	double bias_fc3[LAYER5];

}AlexNet;
```

## The data structure of input and output during learning
```C
    typedef struct Feature
    {
        double input[INPUT][LENGTH_FEATURE0][LENGTH_FEATURE0];

        double layer1_conv[LAYER1][LENGTH_FEATURE1_1][LENGTH_FEATURE1_1];
        double layer1_pool[LAYER1][LENGTH_FEATURE1_2][LENGTH_FEATURE1_2];

        double layer2_conv[LAYER2][LENGTH_FEATURE2_1][LENGTH_FEATURE2_1];
        double layer2_pool[LAYER3][LENGTH_FEATURE2_2][LENGTH_FEATURE2_2];

        double layer3_conv[LAYER4][LENGTH_FEATURE3_1][LENGTH_FEATURE3_1];
        
        double layer4_conv[LAYER5][LENGTH_FEATURE4_1][LENGTH_FEATURE4_1];


        double layer5_conv[LAYER5][LENGTH_FEATURE5_1][LENGTH_FEATURE5_1];
        double layer5_pool[LAYER5][LENGTH_FEATURE5_2][LENGTH_FEATURE5_2];

        double fc1[FC1_OUTPUT];
        double fc2[FC2_OUTPUT];
        double fc3[FC3_OUTPUT];

        double output[OUTPUT];
    }Feature;
```